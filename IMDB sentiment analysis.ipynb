{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e4J918jyhpA0"
   },
   "source": [
    "# Enviromental Setup and Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22701,
     "status": "ok",
     "timestamp": 1554920045014,
     "user": {
      "displayName": "siyun liao",
      "photoUrl": "",
      "userId": "05710455581724734911"
     },
     "user_tz": 240
    },
    "id": "K4L2c2cI4qRA",
    "outputId": "16ab774b-2da3-4aa4-d584-a94241c67791"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "unzip:  cannot find or open gdrive/My Drive/dataset.zip, gdrive/My Drive/dataset.zip.zip or gdrive/My Drive/dataset.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "import nltk\n",
    "import math\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import wordnet\n",
    "from scipy.stats import uniform\n",
    "from scipy.stats import randint\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "!unzip -qq gdrive/My\\ Drive/dataset.zip\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ieGrf-3Fhx_-"
   },
   "source": [
    "# Read data from .txt files and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 577,
     "status": "error",
     "timestamp": 1554920049733,
     "user": {
      "displayName": "siyun liao",
      "photoUrl": "",
      "userId": "05710455581724734911"
     },
     "user_tz": 240
    },
    "id": "RkkVs2Ons8xi",
    "outputId": "52ce5bd3-47b7-4092-a3da-b377a6b48dda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train data to Pandas Dataframe...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e26b0c95e4e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m88\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mtr_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0mte_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mdf_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_raw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e26b0c95e4e7>\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(tp)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mlist_of_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset/train/pos/'"
     ]
    }
   ],
   "source": [
    "def read_data(tp):\n",
    "    print('Reading %s data to Pandas Dataframe...' %(tp))\n",
    "    path = 'dataset/' + tp + '/'\n",
    "    labels = {'pos':1, 'neg':0}\n",
    "  \n",
    "    df = pd.DataFrame()\n",
    "    start = time.time()\n",
    "    if tp == 'train':\n",
    "        for p in labels.keys():\n",
    "            list_of_files = os.listdir(path + p + '/')\n",
    "            for file in list_of_files:\n",
    "                f = open(path + p + '/' + file, 'r')\n",
    "                txt = f.read()\n",
    "                df = df.append([[txt, labels[p]]], ignore_index = True)\n",
    "                f.close()\n",
    "    \n",
    "    else:\n",
    "        list_of_files = os.listdir(path)\n",
    "        for file in list_of_files:\n",
    "            f = open(path + file, 'r')\n",
    "            txt = f.read()\n",
    "            id = int(re.sub('.txt', '', file))\n",
    "            df = df.append([[txt, id+100000]], ignore_index = True)\n",
    "            f.close()\n",
    "      \n",
    "    df.columns = ['text', 'sentiment']\n",
    "    print('Done.')\n",
    "    end = time.time()\n",
    "    print('Time elapsed on reading is', end - start,'\\n')\n",
    "    return df\n",
    "np.random.seed(88)   \n",
    "tr_raw = read_data('train')\n",
    "te_raw = read_data('test')\n",
    "df_raw = pd.concat([tr_raw, te_raw], axis = 0)\n",
    "df_raw.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kQ9GbQs5dziM"
   },
   "outputs": [],
   "source": [
    "#nltk.download('wordnet')\n",
    "def preprocess(text): \n",
    "    text = text.lower().split()\n",
    "#     stops = set(stopwords.words(\"english\"))\n",
    "#     text = [w for w in text if not w in stops and len(w) >= 3]\n",
    "    text = \" \".join(text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"^https?:\\/\\/.*[\\r\\n]*\",\"\", text)\n",
    "    text = text.split()\n",
    "    lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "    stemmed_words = [lemma.lemmatize(word) for word in text]\n",
    "    text = \" \".join(stemmed_words)\n",
    "    return text\n",
    "  \n",
    "df = df_raw.copy()\n",
    "df['text'] = df['text'].map(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0SqfottDFN4z"
   },
   "source": [
    "# Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 190546,
     "status": "ok",
     "timestamp": 1550882535846,
     "user": {
      "displayName": "Yifei Tang",
      "photoUrl": "https://lh5.googleusercontent.com/-kXKbVO-IS64/AAAAAAAAAAI/AAAAAAAAAA8/j4vk8duyhBg/s64/photo.jpg",
      "userId": "04872410556903913477"
     },
     "user_tz": 300
    },
    "id": "t9fZsdPuAtkf",
    "outputId": "3a99bb6a-a902-413f-a998-76e668a0c925"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19692    dave is going through a divorce and his mind w...\n",
       "11457    a wonderful free flowing often lyrical film th...\n",
       "13050    never even knew this movie existed until i fou...\n",
       "16393    watching that lady in ermine i wa wondering wh...\n",
       "21348    2 star for kay francis - - she wonderful ! and...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.loc[df['sentiment']<2]['text'], df.loc[df['sentiment']<2]['sentiment'], train_size=0.75, test_size=0.25)\n",
    "X_train_total = df.loc[df['sentiment']<2]['text'].copy()\n",
    "y_train_total = df.loc[df['sentiment']<2]['sentiment'].copy()\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OCbKR4V2FZJy"
   },
   "source": [
    "# Feature Extraction and Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WEhkB5AYMjrY"
   },
   "outputs": [],
   "source": [
    "def csv_exp(result, name):\n",
    "  csv = result.to_csv(index=False)\n",
    "  f = open(name+'.csv','w')\n",
    "  f.write(csv)\n",
    "  f.close()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DnPmXkRXt7SQ"
   },
   "outputs": [],
   "source": [
    "def accuracy(arr1, arr2):\n",
    "  return 1 - sum(abs(arr1 - arr2))/len(arr1)\n",
    "seed = 88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L6joahr9-cLD"
   },
   "outputs": [],
   "source": [
    "def cv_tabular(result):\n",
    "  dic = {}\n",
    "  for x in result['params'][0]:\n",
    "    dic[x] = []\n",
    "  for x in result['params']:\n",
    "    for key in dic.keys():\n",
    "      dic[key].append(x[key])\n",
    "  cv_df = pd.DataFrame(data = dic)\n",
    "  cv_df['mean_test_score'] = result['mean_test_score']\n",
    "  cv_df['std_test_score'] = result['std_test_score']\n",
    "  cv_df['mean_fit_time'] = result['mean_fit_time']\n",
    "  cv_df = cv_df.sort_values(by = 'mean_test_score')\n",
    "  return cv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PgasK82IaG_1"
   },
   "source": [
    "## Logistic Regression Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "9RkLvBXA1SPT"
   },
   "outputs": [],
   "source": [
    "logreg = Pipeline([\n",
    "    ('vect', CountVectorizer(binary = True)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('norm', Normalizer()),\n",
    "    ('clf', LogisticRegression(C=10)),\n",
    "])\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1508
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1024061,
     "status": "ok",
     "timestamp": 1550883369392,
     "user": {
      "displayName": "Yifei Tang",
      "photoUrl": "https://lh5.googleusercontent.com/-kXKbVO-IS64/AAAAAAAAAAI/AAAAAAAAAA8/j4vk8duyhBg/s64/photo.jpg",
      "userId": "04872410556903913477"
     },
     "user_tz": 300
    },
    "id": "jrY5-uVnTXRr",
    "outputId": "0ba7e234-55ca-432a-8c5c-f332cbea0e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   39.2s\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=-1)]: Done  72 out of  72 | elapsed: 13.8min finished\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My best accuracy is 0.89232\n",
      "Best model is {'clf__penalty': 'l2', 'vect__binary': False, 'vect__max_features': None, 'vect__ngram_range': (1, 1)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf__penalty</th>\n",
       "      <th>vect__binary</th>\n",
       "      <th>vect__max_features</th>\n",
       "      <th>vect__ngram_range</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.774080</td>\n",
       "      <td>0.001363</td>\n",
       "      <td>28.247177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.774827</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>28.160753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.775520</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>18.211167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.775733</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>18.462948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.775787</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>18.281320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.776587</td>\n",
       "      <td>0.001523</td>\n",
       "      <td>18.369485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.819467</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>18.052719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.820107</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>18.169940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.826133</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>18.140384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.827040</td>\n",
       "      <td>0.002952</td>\n",
       "      <td>18.426915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.829067</td>\n",
       "      <td>0.003912</td>\n",
       "      <td>11.503198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.829920</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>14.834449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.830027</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>10.930691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.830720</td>\n",
       "      <td>0.002791</td>\n",
       "      <td>23.474258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.831200</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>15.315727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(3, 3)</td>\n",
       "      <td>0.831680</td>\n",
       "      <td>0.004285</td>\n",
       "      <td>23.232582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.832587</td>\n",
       "      <td>0.003591</td>\n",
       "      <td>11.605850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.832693</td>\n",
       "      <td>0.003591</td>\n",
       "      <td>11.565894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.857920</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>7.409790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.857973</td>\n",
       "      <td>0.001775</td>\n",
       "      <td>7.400644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>l1</td>\n",
       "      <td>True</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.857973</td>\n",
       "      <td>0.001775</td>\n",
       "      <td>7.135290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.861707</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>5.230722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.861707</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>5.240810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>l1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.861707</td>\n",
       "      <td>0.002948</td>\n",
       "      <td>4.913795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.868427</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>11.536016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.869013</td>\n",
       "      <td>0.003427</td>\n",
       "      <td>11.391210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.869387</td>\n",
       "      <td>0.001987</td>\n",
       "      <td>14.497823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.870880</td>\n",
       "      <td>0.003054</td>\n",
       "      <td>12.272934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.872907</td>\n",
       "      <td>0.004440</td>\n",
       "      <td>14.174666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.873387</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>11.891348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.880320</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>4.373055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.880320</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>4.266453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l2</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.880320</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>4.278253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.883520</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>4.990930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.883520</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>4.917766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>l2</td>\n",
       "      <td>False</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.883520</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>4.749144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clf__penalty  vect__binary  vect__max_features vect__ngram_range  \\\n",
       "20           l1          True                 NaN            (3, 3)   \n",
       "29           l1         False                 NaN            (3, 3)   \n",
       "32           l1         False             50000.0            (3, 3)   \n",
       "35           l1         False            100000.0            (3, 3)   \n",
       "26           l1          True            100000.0            (3, 3)   \n",
       "23           l1          True             50000.0            (3, 3)   \n",
       "5            l2          True             50000.0            (3, 3)   \n",
       "14           l2         False             50000.0            (3, 3)   \n",
       "8            l2          True            100000.0            (3, 3)   \n",
       "17           l2         False            100000.0            (3, 3)   \n",
       "34           l1         False            100000.0            (2, 2)   \n",
       "28           l1         False                 NaN            (2, 2)   \n",
       "31           l1         False             50000.0            (2, 2)   \n",
       "11           l2         False                 NaN            (3, 3)   \n",
       "19           l1          True                 NaN            (2, 2)   \n",
       "2            l2          True                 NaN            (3, 3)   \n",
       "25           l1          True            100000.0            (2, 2)   \n",
       "22           l1          True             50000.0            (2, 2)   \n",
       "21           l1          True             50000.0            (1, 1)   \n",
       "18           l1          True                 NaN            (1, 1)   \n",
       "24           l1          True            100000.0            (1, 1)   \n",
       "33           l1         False            100000.0            (1, 1)   \n",
       "30           l1         False             50000.0            (1, 1)   \n",
       "27           l1         False                 NaN            (1, 1)   \n",
       "13           l2         False             50000.0            (2, 2)   \n",
       "4            l2          True             50000.0            (2, 2)   \n",
       "10           l2         False                 NaN            (2, 2)   \n",
       "16           l2         False            100000.0            (2, 2)   \n",
       "1            l2          True                 NaN            (2, 2)   \n",
       "7            l2          True            100000.0            (2, 2)   \n",
       "6            l2          True            100000.0            (1, 1)   \n",
       "3            l2          True             50000.0            (1, 1)   \n",
       "0            l2          True                 NaN            (1, 1)   \n",
       "9            l2         False                 NaN            (1, 1)   \n",
       "15           l2         False            100000.0            (1, 1)   \n",
       "12           l2         False             50000.0            (1, 1)   \n",
       "\n",
       "    mean_test_score  std_test_score  mean_fit_time  \n",
       "20         0.774080        0.001363      28.247177  \n",
       "29         0.774827        0.001411      28.160753  \n",
       "32         0.775520        0.001523      18.211167  \n",
       "35         0.775733        0.002269      18.462948  \n",
       "26         0.775787        0.000723      18.281320  \n",
       "23         0.776587        0.001523      18.369485  \n",
       "5          0.819467        0.001353      18.052719  \n",
       "14         0.820107        0.003166      18.169940  \n",
       "8          0.826133        0.002792      18.140384  \n",
       "17         0.827040        0.002952      18.426915  \n",
       "34         0.829067        0.003912      11.503198  \n",
       "28         0.829920        0.003911      14.834449  \n",
       "31         0.830027        0.003911      10.930691  \n",
       "11         0.830720        0.002791      23.474258  \n",
       "19         0.831200        0.003911      15.315727  \n",
       "2          0.831680        0.004285      23.232582  \n",
       "25         0.832587        0.003591      11.605850  \n",
       "22         0.832693        0.003591      11.565894  \n",
       "21         0.857920        0.001828       7.409790  \n",
       "18         0.857973        0.001775       7.400644  \n",
       "24         0.857973        0.001775       7.135290  \n",
       "33         0.861707        0.002948       5.230722  \n",
       "30         0.861707        0.002948       5.240810  \n",
       "27         0.861707        0.002948       4.913795  \n",
       "13         0.868427        0.002521      11.536016  \n",
       "4          0.869013        0.003427      11.391210  \n",
       "10         0.869387        0.001987      14.497823  \n",
       "16         0.870880        0.003054      12.272934  \n",
       "1          0.872907        0.004440      14.174666  \n",
       "7          0.873387        0.004920      11.891348  \n",
       "6          0.880320        0.000439       4.373055  \n",
       "3          0.880320        0.000439       4.266453  \n",
       "0          0.880320        0.000439       4.278253  \n",
       "9          0.883520        0.001719       4.990930  \n",
       "15         0.883520        0.001719       4.917766  \n",
       "12         0.883520        0.001719       4.749144  "
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 130\n",
    "params_log = {\"vect__ngram_range\": [(1,1),(2,2),(3,3)],\n",
    "              \"vect__binary\":[True, False],\n",
    "              \"vect__max_features\":[None, 50000, 100000],\n",
    "              \"clf__penalty\": [\"l2\", \"l1\"]}\n",
    "logreg_cv = GridSearchCV(logreg, param_grid = params_log, cv=2, verbose = 10, n_jobs = -1)\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "y_pred = logreg_cv.predict(X_test)\n",
    "print('My best accuracy is', accuracy(y_test, y_pred))\n",
    "print('Best model is', logreg_cv.best_params_)\n",
    "cv_tabular(logreg_cv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "37tgCMijMUA2"
   },
   "outputs": [],
   "source": [
    "logreg_result = cv_tabular(logreg_cv.cv_results_)\n",
    "csv_exp(logreg_result, 'Logreg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tNYjJCRPTd_A"
   },
   "source": [
    "## Decision Tree Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tTGFb8NZTu1h"
   },
   "outputs": [],
   "source": [
    "dec_tree = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('norm', Normalizer()),\n",
    "    ('clf-tree', tree.DecisionTreeClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1818910,
     "status": "ok",
     "timestamp": 1550884164272,
     "user": {
      "displayName": "Yifei Tang",
      "photoUrl": "https://lh5.googleusercontent.com/-kXKbVO-IS64/AAAAAAAAAAI/AAAAAAAAAA8/j4vk8duyhBg/s64/photo.jpg",
      "userId": "04872410556903913477"
     },
     "user_tz": 300
    },
    "id": "N1iEank5ro8G",
    "outputId": "4c2bdd68-4c70-4846-c0d3-b9e3c26c888d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 18 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  2.2min\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed: 12.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My accuracy is 0.69552\n",
      "Best model is {'clf-tree__max_depth': None, 'vect__max_features': 10000, 'vect__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "params_dt = {\"vect__ngram_range\": [(1,1),(2,2)],\n",
    "             \"vect__max_features\":[None, 10000, 50000],\n",
    "             \"clf-tree__max_depth\": [None, 500, 5000]}\n",
    "dec_tree_cv = GridSearchCV(dec_tree, param_grid = params_dt, cv=2, verbose = 10, n_jobs = -1)\n",
    "dec_tree_cv.fit(X_train, y_train)\n",
    "y_pred = dec_tree_cv.predict(X_test)\n",
    "print('My accuracy is', accuracy(y_test, y_pred))\n",
    "print('Best model is', dec_tree_cv.best_params_)\n",
    "dt_result = cv_tabular(dec_tree_cv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1818904,
     "status": "ok",
     "timestamp": 1550884164273,
     "user": {
      "displayName": "Yifei Tang",
      "photoUrl": "https://lh5.googleusercontent.com/-kXKbVO-IS64/AAAAAAAAAAI/AAAAAAAAAA8/j4vk8duyhBg/s64/photo.jpg",
      "userId": "04872410556903913477"
     },
     "user_tz": 300
    },
    "id": "XlX7LTuVTKVh",
    "outputId": "7a8d8de3-e8fb-462d-b80a-0643b6494127"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clf-tree__max_depth</th>\n",
       "      <th>vect__max_features</th>\n",
       "      <th>vect__ngram_range</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.642187</td>\n",
       "      <td>0.004252</td>\n",
       "      <td>91.414668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.647573</td>\n",
       "      <td>0.003878</td>\n",
       "      <td>92.497577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.648533</td>\n",
       "      <td>0.004197</td>\n",
       "      <td>91.646705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>500.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.652533</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>22.837389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.654293</td>\n",
       "      <td>0.006437</td>\n",
       "      <td>22.872181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.654453</td>\n",
       "      <td>0.002330</td>\n",
       "      <td>22.857502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.656107</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>34.245579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>500.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.656853</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>33.407316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>0.657120</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>33.167261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.683040</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>18.165090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>500.0</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.684427</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>18.359511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.684640</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>18.320746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.685973</td>\n",
       "      <td>0.002380</td>\n",
       "      <td>18.372676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.686400</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>18.357898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.686560</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>15.659238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.688320</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>18.241943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>500.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.689280</td>\n",
       "      <td>0.003766</td>\n",
       "      <td>15.361407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.690133</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>15.594618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    clf-tree__max_depth  vect__max_features vect__ngram_range  \\\n",
       "1                   NaN                 NaN            (2, 2)   \n",
       "13               5000.0                 NaN            (2, 2)   \n",
       "7                 500.0                 NaN            (2, 2)   \n",
       "9                 500.0             10000.0            (2, 2)   \n",
       "15               5000.0             10000.0            (2, 2)   \n",
       "3                   NaN             10000.0            (2, 2)   \n",
       "17               5000.0             50000.0            (2, 2)   \n",
       "11                500.0             50000.0            (2, 2)   \n",
       "5                   NaN             50000.0            (2, 2)   \n",
       "16               5000.0             50000.0            (1, 1)   \n",
       "10                500.0             50000.0            (1, 1)   \n",
       "6                 500.0                 NaN            (1, 1)   \n",
       "12               5000.0                 NaN            (1, 1)   \n",
       "0                   NaN                 NaN            (1, 1)   \n",
       "14               5000.0             10000.0            (1, 1)   \n",
       "4                   NaN             50000.0            (1, 1)   \n",
       "8                 500.0             10000.0            (1, 1)   \n",
       "2                   NaN             10000.0            (1, 1)   \n",
       "\n",
       "    mean_test_score  std_test_score  mean_fit_time  \n",
       "1          0.642187        0.004252      91.414668  \n",
       "13         0.647573        0.003878      92.497577  \n",
       "7          0.648533        0.004197      91.646705  \n",
       "9          0.652533        0.004677      22.837389  \n",
       "15         0.654293        0.006437      22.872181  \n",
       "3          0.654453        0.002330      22.857502  \n",
       "17         0.656107        0.005263      34.245579  \n",
       "11         0.656853        0.005583      33.407316  \n",
       "5          0.657120        0.008623      33.167261  \n",
       "16         0.683040        0.000834      18.165090  \n",
       "10         0.684427        0.001047      18.359511  \n",
       "6          0.684640        0.002114      18.320746  \n",
       "12         0.685973        0.002380      18.372676  \n",
       "0          0.686400        0.000287      18.357898  \n",
       "14         0.686560        0.001087      15.659238  \n",
       "4          0.688320        0.002273      18.241943  \n",
       "8          0.689280        0.003766      15.361407  \n",
       "2          0.690133        0.000033      15.594618  "
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_exp(dt_result, 'dectree')\n",
    "cv_tabular(dec_tree_cv.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7pTlUJ0NKh9h"
   },
   "source": [
    "## SVM Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eIwIe4c6KlCb"
   },
   "outputs": [],
   "source": [
    "lsvm = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('norm', Normalizer()),\n",
    "    ('clf', LinearSVC(random_state = 0, tol = 1e-7)),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "params_svm = {\"vect__ngram_range\": [(1,1), (1,2),(2,2),(3,3)],\n",
    "              \"vect__binary\":[True, False],\n",
    "              \"vect__max_features\":[None, 50000, 100000],\n",
    "              \"clf__penalty\": [\"l2\"]}\n",
    "lsvm_cv = GridSearchCV(lsvm, param_grid = params_svm, cv=2, verbose = 10, n_jobs = -1)\n",
    "lsvm_cv.fit(X_train, y_train)\n",
    "y_pred = lsvm_cv.predict(X_test)\n",
    "print('My best accuracy is', accuracy(y_test, y_pred))\n",
    "print('Best model is', lsvm_cv.best_params_)\n",
    "cv_tabular(lsvm_cv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "22EnPJSTKedC"
   },
   "outputs": [],
   "source": [
    "lsvm_result = cv_tabular(lsvm_cv.cv_results_)\n",
    "csv_exp(lsvm_result, 'SVM')\n",
    "lsvm_cv.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rko6jcKENq6X"
   },
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2450418,
     "status": "ok",
     "timestamp": 1550884795814,
     "user": {
      "displayName": "Yifei Tang",
      "photoUrl": "https://lh5.googleusercontent.com/-kXKbVO-IS64/AAAAAAAAAAI/AAAAAAAAAA8/j4vk8duyhBg/s64/photo.jpg",
      "userId": "04872410556903913477"
     },
     "user_tz": 300
    },
    "id": "lS2L0OqvQS8f",
    "outputId": "3bee8c4c-ec4e-4fce-de6a-406c539f866c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6250 / 6250 accuracy on validation set for naive bayes is  0.85328\n"
     ]
    }
   ],
   "source": [
    "class NaiveBayes:\n",
    "  def __init__(self, X_train, y_train):\n",
    "    self.X_train = X_train\n",
    "    self.y_train = y_train\n",
    "    self.count_vect = None\n",
    "    self.X_train_counts = None\n",
    "    \n",
    "    #prior\n",
    "    self.pos_count = -1\n",
    "    self.neg_count = -1\n",
    "    self.doc_count = -1\n",
    "    self.prior_log_pos = -1\n",
    "    self.prior_log_neg = -1\n",
    "    \n",
    "    #In how many documents among all Pos corpus/ Neg corpus that we see a word\n",
    "    self.occurrence_count_pos = None\n",
    "    self.occurrence_count_neg = None\n",
    "    \n",
    "    #Log likelihood for each text feature\n",
    "    self.feature_log_likelihood_matrix_pos = None\n",
    "    self.feature_log_likelihood_matrix_neg = None\n",
    "    self.feature_log_likelihood_matrix_not_occurred_pos = None\n",
    "    self.feature_log_likelihood_matrix_not_occurred_neg = None\n",
    "    \n",
    "    #The sum of P(Xi=0|y=1), The sum of P(Xi=0|y=0)\n",
    "    self.sum_feature_log_likelihood_matrix_not_occurred_pos = 0\n",
    "    self.sum_feature_log_likelihood_matrix_not_occurred_neg = 0\n",
    "  \n",
    "  '''Get bag of words in order to calculate binary occurrence'''\n",
    "  def get_BOW(self, X_train):\n",
    "    self.count_vect = CountVectorizer(binary=False).fit(X_train)\n",
    "    X_train_counts = self.count_vect.transform(X_train)\n",
    "    return X_train_counts\n",
    "  \n",
    "  #log(theta)\n",
    "  def log_likelihood_features(self, occurrence_count,y_count, doc_count):\n",
    "    vfunc = np.vectorize(lambda x: math.log(float(x+1)/(y_count+2)))\n",
    "    occurrence_count = vfunc(occurrence_count)\n",
    "    return occurrence_count\n",
    "  \n",
    "  #log(1-theta)\n",
    "  def log_likelihood_features_not_occurred(self, occurrence_count,y_count, doc_count):\n",
    "    vfunc = np.vectorize(lambda x: math.log(1-(float(x+1)/(y_count+2))))\n",
    "    occurrence_count = vfunc(occurrence_count)\n",
    "    return occurrence_count\n",
    "  \n",
    "  def X_train_counts_filter_row(self,y_train_filtered, index_dict, X_train_counts):\n",
    "    return X_train_counts[[index_dict[document_id] for document_id in y_train_filtered.index.values.tolist()]]\n",
    "    \n",
    "  def get_occurrence_count(self):\n",
    "    index_dict = dict(zip(self.y_train.index.values.tolist(), range(self.X_train_counts.shape[0])))\n",
    "    \n",
    "    X_train_counts_pos = self.X_train_counts_filter_row(\n",
    "        self.y_train.loc[y_train == 1],\n",
    "        index_dict,\n",
    "        self.X_train_counts)\n",
    "\n",
    "    X_train_counts_neg = self.X_train_counts_filter_row(\n",
    "        self.y_train.loc[y_train == 0],\n",
    "        index_dict,\n",
    "        self.X_train_counts)\n",
    "    #occurrence_count: the counts of all non-zero entry of each column in the sparse matrix\n",
    "    self.occurrence_count_pos = (X_train_counts_pos != 0).sum(0)\n",
    "    self.occurrence_count_neg = (X_train_counts_neg != 0).sum(0)\n",
    "\n",
    "  def train(self):\n",
    "    self.pos_count =  len(y_train[y_train==1])\n",
    "    self.neg_count = len(y_train[y_train==0])\n",
    "    self.doc_count = self.pos_count + self.neg_count\n",
    "    \n",
    "    self.X_train_counts = self.get_BOW(self.X_train)\n",
    "\n",
    "    self.prior_log_pos = math.log(self.pos_count/self.doc_count)\n",
    "    self.prior_log_neg = math.log(self.neg_count/self.doc_count)\n",
    "\n",
    "    self.get_occurrence_count()\n",
    "    self.feature_log_likelihood_matrix_pos = self.log_likelihood_features(self.occurrence_count_pos,self.pos_count,self.doc_count)\n",
    "    self.feature_log_likelihood_matrix_neg = self.log_likelihood_features(self.occurrence_count_neg,self.neg_count,self.doc_count)\n",
    "\n",
    "    self.feature_log_likelihood_matrix_not_occurred_pos = self.log_likelihood_features_not_occurred(self.occurrence_count_pos,self.pos_count,self.doc_count)\n",
    "    self.feature_log_likelihood_matrix_not_occurred_neg = self.log_likelihood_features_not_occurred(self.occurrence_count_neg,self.neg_count,self.doc_count)\n",
    "\n",
    "    self.sum_feature_log_likelihood_matrix_not_occurred_pos = self.feature_log_likelihood_matrix_not_occurred_pos.sum()\n",
    "    self.sum_feature_log_likelihood_matrix_not_occurred_neg = self.feature_log_likelihood_matrix_not_occurred_neg.sum()\n",
    "\n",
    "  def predict(self,X_test):\n",
    "    y_pred = []\n",
    "    X_test_counts = self.count_vect.transform(X_test)\n",
    "    nrows, ncols = X_test_counts.shape\n",
    "    process = 0\n",
    "    for row in X_test_counts:\n",
    "      likelihood_pos_occur = 0\n",
    "      likelihood_neg_occur = 0\n",
    "      likelihood_pos_not_occur = self.sum_feature_log_likelihood_matrix_not_occurred_pos\n",
    "      likelihood_neg_not_occur = self.sum_feature_log_likelihood_matrix_not_occurred_neg\n",
    "\n",
    "      for ele in row:\n",
    "        for word_index in ele.indices:\n",
    "          likelihood_pos_occur += self.feature_log_likelihood_matrix_pos.item(word_index)\n",
    "          likelihood_neg_occur += self.feature_log_likelihood_matrix_neg.item(word_index)\n",
    "          likelihood_pos_not_occur -= self.feature_log_likelihood_matrix_not_occurred_pos.item(word_index)\n",
    "          likelihood_neg_not_occur -= self.feature_log_likelihood_matrix_not_occurred_neg.item(word_index)\n",
    "\n",
    "      if((likelihood_pos_occur+likelihood_pos_not_occur)\n",
    "         >(likelihood_neg_occur+likelihood_neg_not_occur)): y_pred.append(1)\n",
    "      else: y_pred.append(0)\n",
    "      process += 1\n",
    "      print('\\r %d / %d '%(process,nrows), end='')\n",
    "    return y_pred\n",
    "           \n",
    "    \n",
    "nb_estimator = NaiveBayes(X_train,y_train)\n",
    "nb_estimator.train()\n",
    "y_pred = nb_estimator.predict(X_test)\n",
    "print(\"accuracy on validation set for naive bayes is \", accuracy(y_test, y_pred))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P2t4f-7rG0g6"
   },
   "source": [
    "# Output result to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1969
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2464389,
     "status": "ok",
     "timestamp": 1550884809793,
     "user": {
      "displayName": "Yifei Tang",
      "photoUrl": "https://lh5.googleusercontent.com/-kXKbVO-IS64/AAAAAAAAAAI/AAAAAAAAAA8/j4vk8duyhBg/s64/photo.jpg",
      "userId": "04872410556903913477"
     },
     "user_tz": 300
    },
    "id": "sn1ks1_oY_Gl",
    "outputId": "55690442-abed-46e7-d912-a3568f7140fc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6965</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12063</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17179</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19584</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21023</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7394</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19247</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10654</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5598</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23128</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12836</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21109</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3774</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16347</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21999</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14049</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10784</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11008</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2858</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13040</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14554</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14378</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8475</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11035</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15623</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3560</th>\n",
       "      <td>24970</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20053</th>\n",
       "      <td>24971</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11661</th>\n",
       "      <td>24972</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9732</th>\n",
       "      <td>24973</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8342</th>\n",
       "      <td>24974</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17908</th>\n",
       "      <td>24975</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12035</th>\n",
       "      <td>24976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13989</th>\n",
       "      <td>24977</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13644</th>\n",
       "      <td>24978</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14443</th>\n",
       "      <td>24979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13208</th>\n",
       "      <td>24980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24656</th>\n",
       "      <td>24981</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17436</th>\n",
       "      <td>24982</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13164</th>\n",
       "      <td>24983</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15933</th>\n",
       "      <td>24984</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>24985</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13390</th>\n",
       "      <td>24986</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14627</th>\n",
       "      <td>24987</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20744</th>\n",
       "      <td>24988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>24989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11751</th>\n",
       "      <td>24990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>24991</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22189</th>\n",
       "      <td>24992</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8351</th>\n",
       "      <td>24993</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3348</th>\n",
       "      <td>24994</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23495</th>\n",
       "      <td>24995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23898</th>\n",
       "      <td>24996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22972</th>\n",
       "      <td>24997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24867</th>\n",
       "      <td>24998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21246</th>\n",
       "      <td>24999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  Category\n",
       "6965       0         0\n",
       "12063      1         0\n",
       "17179      2         0\n",
       "19584      3         0\n",
       "21023      4         1\n",
       "7394       5         0\n",
       "23997      6         0\n",
       "824        7         0\n",
       "19247      8         0\n",
       "10654      9         0\n",
       "5598      10         0\n",
       "23128     11         0\n",
       "12836     12         1\n",
       "21109     13         0\n",
       "2017      14         1\n",
       "3774      15         0\n",
       "5542      16         0\n",
       "16347     17         1\n",
       "21999     18         0\n",
       "14049     19         0\n",
       "10784     20         0\n",
       "11008     21         0\n",
       "2858      22         0\n",
       "13040     23         1\n",
       "14554     24         1\n",
       "785       25         1\n",
       "14378     26         0\n",
       "8475      27         0\n",
       "11035     28         0\n",
       "15623     29         1\n",
       "...      ...       ...\n",
       "3560   24970         0\n",
       "20053  24971         0\n",
       "11661  24972         1\n",
       "9732   24973         0\n",
       "8342   24974         1\n",
       "17908  24975         1\n",
       "12035  24976         0\n",
       "13989  24977         1\n",
       "13644  24978         0\n",
       "14443  24979         1\n",
       "13208  24980         1\n",
       "24656  24981         0\n",
       "17436  24982         0\n",
       "13164  24983         1\n",
       "15933  24984         1\n",
       "144    24985         0\n",
       "13390  24986         1\n",
       "14627  24987         0\n",
       "20744  24988         0\n",
       "2207   24989         0\n",
       "11751  24990         1\n",
       "4380   24991         1\n",
       "22189  24992         1\n",
       "8351   24993         0\n",
       "3348   24994         1\n",
       "23495  24995         0\n",
       "23898  24996         1\n",
       "22972  24997         1\n",
       "24867  24998         1\n",
       "21246  24999         1\n",
       "\n",
       "[25000 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def csv_make(model):\n",
    "  result = df.loc[df['sentiment']>2]\n",
    "  pred = model.predict(result['text'])\n",
    "  \n",
    "  a = {'Id':result['sentiment'], 'Category':pred}\n",
    "  output = pd.DataFrame(data = a)\n",
    "  output = output[['Id', 'Category']]\n",
    "  output['Id'] = output['Id'].map(lambda x:x-100000)\n",
    "  output = output.sort_values(by=['Id'])\n",
    "  csv = output.to_csv(index=False)\n",
    "  f = open('prediction.csv','w')\n",
    "  f.write(csv)\n",
    "  f.close()\n",
    "  return output\n",
    "\n",
    "\n",
    "csv_make(lsvm_cv)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "IMDB sentiment analysis.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
